{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b568712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Grand Slam matches…\n",
      "Loading and stacking ranking doubles files…\n",
      "Attaching ranks (tournament-year)…\n",
      "Wrote unmatched names list to: C:/Users/ALESSANDRO/Documents/GitHub/tennis-homophily/data/atp/_unmatched_names_for_manual_mapping.txt\n",
      "Saving to C:/Users/ALESSANDRO/Documents/GitHub/tennis-homophily/data/atp/grand_slam_matches_with_ranks_2018_2023.xlsx …\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from getpass import getuser\n",
    "\n",
    "# =============================\n",
    "# CONFIG\n",
    "# =============================\n",
    "USER = getuser()\n",
    "INPUT_DIR = f\"C:/Users/{USER}/Documents/GitHub/tennis-homophily/data/atp/\"\n",
    "GRAND_SLAM_FILE = os.path.join(INPUT_DIR, \"grand_slam_matches_2018_2023.xlsx\")\n",
    "OUTPUT_FILE = os.path.join(INPUT_DIR, \"grand_slam_matches_with_ranks_2018_2023.xlsx\")\n",
    "\n",
    "# Ranking file columns (edit if headers differ)\n",
    "RANKING_PLAYER_COL = \"Player\"     # e.g. \"J. Cabal\"\n",
    "RANKING_DATE_COL   = \"DateWeek\"   # Monday of the ATP ranking week\n",
    "RANKING_VALUE_COL  = \"Rank\"       # numeric rank\n",
    "\n",
    "# If your ranking files already have tournament/year columns, rename here if needed\n",
    "RANKING_TOURN_CANDIDATES = [\"tournament\", \"Tournament\", \"event\", \"Event\"]\n",
    "RANKING_YEAR_CANDIDATES  = [\"year\", \"Year\", \"season\", \"Season\"]\n",
    "\n",
    "# Keep ALL ranking columns by default. If you want a subset, list it here.\n",
    "PROFILE_KEEP_WHITELIST = []  # e.g. [\"W-L YTD\",\"W-L Career\",\"Titles YTD\",\"Titles Career\",\"DOB\",\"Country\",\"Plays\",\"Coach\"]\n",
    "\n",
    "# If True, strip diacritics in names so \"Pavlásek\" == \"Pavlasek\"\n",
    "STRIP_ACCENTS = True\n",
    "\n",
    "# Optional manual disambiguations (both sides use \"first-initial lastname\" lowercased)\n",
    "MANUAL_KEY_MAP = {\n",
    "    \"a pavlasek\": \"a pavlasek\",   # handles \"-2A. Pavlasek\" vs \"Adam Pavlasek\"\n",
    "    # add more here\n",
    "}\n",
    "\n",
    "# =============================\n",
    "# Helpers: text normalization\n",
    "# =============================\n",
    "def strip_accents(s):\n",
    "    if s is None:\n",
    "        return s\n",
    "    s = str(s)\n",
    "    return \"\".join(c for c in unicodedata.normalize(\"NFKD\", s) if not unicodedata.combining(c))\n",
    "\n",
    "def normalize_spaces(s):\n",
    "    return re.sub(r\"\\s+\", \" \", str(s)).strip()\n",
    "\n",
    "def _maybe_strip_accents(s):\n",
    "    return strip_accents(s) if STRIP_ACCENTS else s\n",
    "\n",
    "def strip_parentheses_payload(name):\n",
    "    \"\"\"Remove '(11)' etc.\"\"\"\n",
    "    if pd.isna(name):\n",
    "        return name\n",
    "    return re.sub(r\"\\([^)]*\\)\", \"\", str(name)).strip()\n",
    "\n",
    "def to_initial_last_key_from_full(fullname):\n",
    "    \"\"\"'Juan Sebastian Cabal(11)' -> 'j cabal'\"\"\"\n",
    "    if pd.isna(fullname) or not str(fullname).strip():\n",
    "        return None\n",
    "    s = normalize_spaces(strip_parentheses_payload(fullname)).replace(\"-\", \" \")\n",
    "    s = _maybe_strip_accents(s)\n",
    "    parts = [p for p in s.split(\" \") if p]\n",
    "    if not parts:\n",
    "        return None\n",
    "    return f\"{parts[0][0].lower()} {parts[-1].lower()}\"\n",
    "\n",
    "def clean_ranking_player_raw(raw):\n",
    "    \"\"\"Drop junk prefixes like '-2' or '1 ' → keep 'A. Pavlasek'\"\"\"\n",
    "    if pd.isna(raw) or not str(raw).strip():\n",
    "        return None\n",
    "    s = re.sub(r\"^[^A-Za-z]+\", \"\", str(raw))\n",
    "    return normalize_spaces(s)\n",
    "\n",
    "def to_initial_last_key_from_initialdot(name):\n",
    "    \"\"\"'J. Cabal' or 'J Cabal' -> 'j cabal'\"\"\"\n",
    "    if pd.isna(name) or not str(name).strip():\n",
    "        return None\n",
    "    s = normalize_spaces(name).replace(\".\", \"\").replace(\"-\", \" \")\n",
    "    s = _maybe_strip_accents(s)\n",
    "    parts = [p for p in s.split(\" \") if p]\n",
    "    if not parts:\n",
    "        return None\n",
    "    if len(parts) == 1:\n",
    "        return f\"{parts[0][0].lower()} {parts[0].lower()}\"\n",
    "    return f\"{parts[0][0].lower()} {parts[-1].lower()}\"\n",
    "\n",
    "def gs_key(name):\n",
    "    key = to_initial_last_key_from_full(name)\n",
    "    return MANUAL_KEY_MAP.get(key, key)\n",
    "\n",
    "def rk_key(name):\n",
    "    return to_initial_last_key_from_initialdot(clean_ranking_player_raw(name))\n",
    "\n",
    "def normalize_tournament(s):\n",
    "    \"\"\"Simple tournament normalizer: lowercase, strip, collapse spaces, strip accents.\"\"\"\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    s = normalize_spaces(str(s)).lower()\n",
    "    s = _maybe_strip_accents(s)\n",
    "    # strip some common punctuation\n",
    "    s = re.sub(r\"[–—-]\", \" \", s)\n",
    "    s = normalize_spaces(s)\n",
    "    return s\n",
    "\n",
    "# =============================\n",
    "# Helpers: profile-field cleaning\n",
    "# =============================\n",
    "DOB_PAT = re.compile(r\"\\((\\d{4})[/-](\\d{1,2})[/-](\\d{1,2})\\)\")\n",
    "KG_PAT  = re.compile(r\"\\((\\d{2,3})\\s*kg\\)\", flags=re.I)\n",
    "CM_PAT  = re.compile(r\"\\((\\d{2,3})\\s*cm\\)\", flags=re.I)\n",
    "\n",
    "def extract_dob_from_age(age_val):\n",
    "    if pd.isna(age_val):\n",
    "        return None\n",
    "    m = DOB_PAT.search(str(age_val))\n",
    "    if not m:\n",
    "        return None\n",
    "    y, mo, d = m.groups()\n",
    "    try:\n",
    "        return pd.Timestamp(int(y), int(mo), int(d)).strftime(\"%Y-%m-%d\")\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def extract_kg(weight_val):\n",
    "    if pd.isna(weight_val):\n",
    "        return None\n",
    "    s = str(weight_val)\n",
    "    m = KG_PAT.search(s) or re.search(r\"(\\d{2,3})\\s*kg\", s, flags=re.I)\n",
    "    return float(m.group(1)) if m else None\n",
    "\n",
    "def extract_cm(height_val):\n",
    "    if pd.isna(height_val):\n",
    "        return None\n",
    "    s = str(height_val)\n",
    "    m = CM_PAT.search(s) or re.search(r\"(\\d{2,3})\\s*cm\", s, flags=re.I)\n",
    "    return float(m.group(1)) if m else None\n",
    "\n",
    "# =============================\n",
    "# Load Grand Slam\n",
    "# =============================\n",
    "print(\"Loading Grand Slam matches…\")\n",
    "if not os.path.exists(GRAND_SLAM_FILE):\n",
    "    raise FileNotFoundError(f\"Grand Slam file not found: {GRAND_SLAM_FILE}\")\n",
    "\n",
    "gs = pd.read_excel(GRAND_SLAM_FILE)\n",
    "\n",
    "# ensure year\n",
    "if \"year\" not in gs.columns:\n",
    "    if \"date\" in gs.columns:\n",
    "        gs[\"year\"] = gs[\"date\"].astype(str).str.extract(r\"([12][0-9]{3})\").astype(int)\n",
    "    else:\n",
    "        raise KeyError(\"Grand Slam file needs a 'year' or a parsable 'date' column.\")\n",
    "\n",
    "# normalize tournament key\n",
    "if \"tournament\" not in gs.columns:\n",
    "    raise KeyError(\"Grand Slam file must have a 'tournament' column.\")\n",
    "gs[\"tourn_key\"] = gs[\"tournament\"].map(normalize_tournament)\n",
    "\n",
    "gs = gs.reset_index().rename(columns={\"index\": \"match_id\"})\n",
    "\n",
    "# =============================\n",
    "# Load & clean ranking files\n",
    "# =============================\n",
    "print(\"Loading and stacking ranking doubles files…\")\n",
    "ranking_files = sorted(glob.glob(os.path.join(INPUT_DIR, \"ranking_doubles_*.xlsx\")))\n",
    "if not ranking_files:\n",
    "    raise FileNotFoundError(\"No ranking_doubles_*.xlsx files found in INPUT_DIR\")\n",
    "\n",
    "rk_rows = []\n",
    "for fp in ranking_files:\n",
    "    df = pd.read_excel(fp)\n",
    "\n",
    "    # Required base columns\n",
    "    missing = [c for c in [RANKING_PLAYER_COL, RANKING_DATE_COL, RANKING_VALUE_COL] if c not in df.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing columns {missing} in ranking file {os.path.basename(fp)}\")\n",
    "\n",
    "    # Keep ALL columns or whitelist subset\n",
    "    if PROFILE_KEEP_WHITELIST:\n",
    "        base_cols = {RANKING_PLAYER_COL, RANKING_DATE_COL, RANKING_VALUE_COL}\n",
    "        keep_cols = list(base_cols.union([c for c in PROFILE_KEEP_WHITELIST if c in df.columns]))\n",
    "        df = df[keep_cols].copy()\n",
    "    else:\n",
    "        df = df.copy()\n",
    "\n",
    "    # Profile cleaning\n",
    "    if \"Age\" in df.columns:\n",
    "        dob_from_age = df[\"Age\"].apply(extract_dob_from_age)\n",
    "        if \"DOB\" in df.columns:\n",
    "            df[\"DOB\"] = df[\"DOB\"].where(df[\"DOB\"].notna() & (df[\"DOB\"].astype(str).str.len() > 0), dob_from_age)\n",
    "        else:\n",
    "            df[\"DOB\"] = dob_from_age\n",
    "        df.drop(columns=[\"Age\"], inplace=True)\n",
    "\n",
    "    if \"Weight\" in df.columns:\n",
    "        df[\"WeightKg\"] = df[\"Weight\"].apply(extract_kg)\n",
    "        df.drop(columns=[\"Weight\"], inplace=True)\n",
    "\n",
    "    if \"Height\" in df.columns:\n",
    "        df[\"HeightCm\"] = df[\"Height\"].apply(extract_cm)\n",
    "        df.drop(columns=[\"Height\"], inplace=True)\n",
    "\n",
    "    # Date & key\n",
    "    df[RANKING_DATE_COL] = pd.to_datetime(df[RANKING_DATE_COL], errors=\"coerce\").dt.tz_localize(None)\n",
    "    df[\"player_key\"] = df[RANKING_PLAYER_COL].map(rk_key)\n",
    "\n",
    "    # tournament column (case-insensitive search)\n",
    "    rk_tourn_col = next((c for c in RANKING_TOURN_CANDIDATES if c in df.columns), None)\n",
    "    if rk_tourn_col is None:\n",
    "        raise KeyError(f\"No tournament column found in {os.path.basename(fp)}. Tried {RANKING_TOURN_CANDIDATES}\")\n",
    "\n",
    "    df[\"tourn_key\"] = df[rk_tourn_col].map(normalize_tournament)\n",
    "\n",
    "    # year column (use existing if present; else derive from DateWeek)\n",
    "    rk_year_col = next((c for c in RANKING_YEAR_CANDIDATES if c in df.columns), None)\n",
    "    if rk_year_col is None:\n",
    "        df[\"year\"] = df[RANKING_DATE_COL].dt.year\n",
    "    else:\n",
    "        df[\"year\"] = pd.to_numeric(df[rk_year_col], errors=\"coerce\")\n",
    "\n",
    "    df = df.dropna(subset=[\"player_key\", RANKING_DATE_COL, \"tourn_key\", \"year\"]).copy()\n",
    "\n",
    "    rk_rows.append(df)\n",
    "\n",
    "rk = pd.concat(rk_rows, ignore_index=True)\n",
    "\n",
    "# For each (player_key, tourn_key, year), keep the latest DateWeek row to avoid duplicates\n",
    "rk = rk.sort_values([ \"player_key\", \"tourn_key\", \"year\", RANKING_DATE_COL ], kind=\"mergesort\")\n",
    "rk_latest = rk.groupby([\"player_key\", \"tourn_key\", \"year\"], as_index=False).tail(1).reset_index(drop=True)\n",
    "\n",
    "# =============================\n",
    "# Merge by (player_key, tournament, year)\n",
    "# =============================\n",
    "def attach_rank_for(gs_df, player_col, out_prefix):\n",
    "    tmp = gs_df[[\"match_id\", \"tourn_key\", \"year\", player_col]].copy()\n",
    "    tmp[\"player_key\"] = tmp[player_col].map(gs_key)\n",
    "    tmp = tmp.dropna(subset=[\"player_key\", \"tourn_key\", \"year\"]).copy()\n",
    "\n",
    "    # bring all ranking columns except helper columns & raw keys\n",
    "    rk_cols = [c for c in rk_latest.columns if c not in (\"player_key\", \"tourn_key\", \"year\")]\n",
    "\n",
    "    merged = tmp.merge(\n",
    "        rk_latest[[\"player_key\", \"tourn_key\", \"year\"] + rk_cols],\n",
    "        on=[\"player_key\", \"tourn_key\", \"year\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # add prefixed columns\n",
    "    out = gs_df.copy()\n",
    "    for c in rk_cols:\n",
    "        out[f\"{out_prefix}{c}\"] = merged[c].values\n",
    "    return out\n",
    "\n",
    "print(\"Attaching ranks (tournament-year)…\")\n",
    "roles = [\n",
    "    (\"winners_p1\", \"winners_p1_\"),\n",
    "    (\"winners_p2\", \"winners_p2_\"),\n",
    "    (\"losers_p1\",  \"losers_p1_\"),\n",
    "    (\"losers_p2\",  \"losers_p2_\"),\n",
    "]\n",
    "for col, prefix in roles:\n",
    "    if col not in gs.columns:\n",
    "        raise KeyError(f\"Column '{col}' is missing from Grand Slam file.\")\n",
    "    gs = attach_rank_for(gs, col, prefix)\n",
    "\n",
    "# =============================\n",
    "# Unmatched names helper list\n",
    "# =============================\n",
    "problem_names = set()\n",
    "for col, prefix in roles:\n",
    "    rank_col = f\"{prefix}{RANKING_VALUE_COL}\"   # e.g. winners_p1_Rank\n",
    "    if rank_col in gs.columns:\n",
    "        mask = gs[rank_col].isna()\n",
    "        problem_names.update(gs.loc[mask, col].dropna().unique().tolist())\n",
    "\n",
    "if problem_names:\n",
    "    problems_path = os.path.join(INPUT_DIR, \"_unmatched_names_for_manual_mapping.txt\")\n",
    "    with open(problems_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for n in sorted(problem_names):\n",
    "            f.write(str(n) + \"\\n\")\n",
    "    print(f\"Wrote unmatched names list to: {problems_path}\")\n",
    "\n",
    "# =============================\n",
    "# Save\n",
    "# =============================\n",
    "print(f\"Saving to {OUTPUT_FILE} …\")\n",
    "with pd.ExcelWriter(OUTPUT_FILE, engine=\"xlsxwriter\") as xlw:\n",
    "    gs.to_excel(xlw, index=False, sheet_name=\"matches_with_ranks\")\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
