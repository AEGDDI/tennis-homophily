{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfba8b18",
   "metadata": {},
   "source": [
    "Filter the dates and consider only data after 2019, trying to consider only one date for each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "575002e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highest_dates(date_values):\n",
    "    highest_dates = {}\n",
    "    for date in date_values:\n",
    "        year_month = date[:7]  # Extract the year and month part of the date\n",
    "        day = int(date[-2:])  # Extract the day part of the date and convert to an integer\n",
    "\n",
    "        # If the current date has a day greater than the stored date for the same year and month,\n",
    "        # update the highest_dates dictionary with the current date\n",
    "        if year_month not in highest_dates or day > highest_dates[year_month]:\n",
    "            highest_dates[year_month] = day\n",
    "\n",
    "    # Combine the year and month with the highest day to form the final list of dates\n",
    "    highest_dates_list = [f\"{year_month}-{highest_day:02d}\" for year_month, highest_day in highest_dates.items()]\n",
    "\n",
    "    return highest_dates_list\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b3adb83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2023-07-31', '2023-06-26', '2023-05-29', '2023-04-24', '2023-03-20', '2023-02-27', '2023-01-30', '2022-12-26', '2022-11-28', '2022-10-31', '2022-09-26', '2022-08-29', '2022-07-25', '2022-06-27', '2022-05-23', '2022-04-25', '2022-03-21', '2022-02-28', '2022-01-31', '2021-12-27', '2021-11-29', '2021-10-25', '2021-09-27', '2021-08-30', '2021-07-26', '2021-06-28', '2021-05-31', '2021-04-26', '2021-03-22', '2021-02-22', '2021-01-25', '2020-12-28', '2020-11-30', '2020-10-26', '2020-09-28', '2020-08-31', '2020-03-16', '2020-02-24', '2020-01-20']\n",
      "List of Dates:\n",
      "2023-07-31\n",
      "2023-06-26\n",
      "2023-05-29\n",
      "2023-04-24\n",
      "2023-03-20\n",
      "2023-02-27\n",
      "2023-01-30\n",
      "2022-12-26\n",
      "2022-11-28\n",
      "2022-10-31\n",
      "2022-09-26\n",
      "2022-08-29\n",
      "2022-07-25\n",
      "2022-06-27\n",
      "2022-05-23\n",
      "2022-04-25\n",
      "2022-03-21\n",
      "2022-02-28\n",
      "2022-01-31\n",
      "2021-12-27\n",
      "2021-11-29\n",
      "2021-10-25\n",
      "2021-09-27\n",
      "2021-08-30\n",
      "2021-07-26\n",
      "2021-06-28\n",
      "2021-05-31\n",
      "2021-04-26\n",
      "2021-03-22\n",
      "2021-02-22\n",
      "2021-01-25\n",
      "2020-12-28\n",
      "2020-11-30\n",
      "2020-10-26\n",
      "2020-09-28\n",
      "2020-08-31\n",
      "2020-03-16\n",
      "2020-02-24\n",
      "2020-01-20\n",
      "Rank Range: 1-5000, Rank Date: 2023-07-31 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2023-07-31.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2023-06-26 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2023-06-26.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2023-05-29 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2023-05-29.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2023-04-24 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2023-04-24.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2023-03-20 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2023-03-20.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2023-02-27 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2023-02-27.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2023-01-30 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2023-01-30.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2022-12-26 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2022-12-26.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2022-11-28 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2022-11-28.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2022-10-31 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2022-10-31.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2022-09-26 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2022-09-26.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2022-08-29 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2022-08-29.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2022-07-25 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2022-07-25.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2022-06-27 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2022-06-27.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2022-05-23 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2022-05-23.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2022-04-25 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2022-04-25.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2022-03-21 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2022-03-21.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2022-02-28 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2022-02-28.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2022-01-31 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2022-01-31.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2021-12-27 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2021-12-27.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2021-11-29 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2021-11-29.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2021-10-25 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2021-10-25.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2021-09-27 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2021-09-27.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2021-08-30 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2021-08-30.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2021-07-26 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2021-07-26.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2021-06-28 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2021-06-28.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2021-05-31 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2021-05-31.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2021-04-26 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2021-04-26.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2021-03-22 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2021-03-22.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2021-02-22 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2021-02-22.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2021-01-25 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2021-01-25.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2020-12-28 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2020-12-28.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2020-11-30 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2020-11-30.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2020-10-26 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2020-10-26.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2020-09-28 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2020-09-28.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2020-08-31 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2020-08-31.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2020-03-16 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2020-03-16.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2020-02-24 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2020-02-24.csv\n",
      "\n",
      "Rank Range: 1-5000, Rank Date: 2020-01-20 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2020-01-20.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "chrome_driver_path = \"C:\\\\Users\\\\ALESSANDRO\\\\Downloads\\\\chromedriver.exe\"\n",
    "output_folder = \"C:\\\\Users\\\\ALESSANDRO\\\\Documents\\\\GitHub\\\\tennis-homophily\\\\data\\\\atp\"\n",
    "\n",
    "# Use the Service object for ChromeDriver\n",
    "service = Service(chrome_driver_path)\n",
    "\n",
    "try:\n",
    "    # Initialize the list of dates to be scraped\n",
    "    date_values = []\n",
    "\n",
    "    # Open the first part to get the list of dates\n",
    "    with webdriver.Chrome(service=service) as driver1:\n",
    "        # Open the URL and wait for the content to load\n",
    "        driver1.get(\"https://www.atptour.com/en/rankings/doubles?rankRange=1-5000\")\n",
    "        WebDriverWait(driver1, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"mega-table\")))\n",
    "\n",
    "        # Find the date dropdown menu and retrieve the date options\n",
    "        date_dropdown_ul = WebDriverWait(driver1, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"ul[data-value='rankDate']\"))\n",
    "        )\n",
    "        date_options = date_dropdown_ul.find_elements(By.TAG_NAME, \"li\")\n",
    "        \n",
    "        # Extract date values from the dropdown and store them in a list\n",
    "#         date_values = [option.get_attribute(\"data-value\") for option in date_options]\n",
    "\n",
    "        # Extract date values from the dropdown and store them in a list - applying year filter\n",
    "        for option in date_options:\n",
    "            date_value = option.get_attribute(\"data-value\")\n",
    "            if date_value is None:\n",
    "                continue\n",
    "            try:\n",
    "                year = int(date_value[:4])\n",
    "            except ValueError:\n",
    "                continue\n",
    "            if year > 2019:\n",
    "                date_values.append(date_value)\n",
    "                \n",
    "    # Filter the dates to keep only the highest number for each pair of year and month\n",
    "    filtered_dates = get_highest_dates(date_values)\n",
    "\n",
    "\n",
    "    print(\"List of Dates:\")\n",
    "    for date in filtered_dates :\n",
    "        print(date)\n",
    "\n",
    "    # Now, loop through different dates and scrape the data\n",
    "    for date in filtered_dates :\n",
    "        # Form the complete URL with the selected date\n",
    "        complete_url = f\"https://www.atptour.com/en/rankings/doubles?rankRange=1-5000&rankDate={date}\"\n",
    "\n",
    "        # Open a new WebDriver for each date\n",
    "        with webdriver.Chrome(service=service) as driver2:\n",
    "            # Open the URL and wait for the content to load\n",
    "            driver2.get(complete_url)\n",
    "            time.sleep(5)  # Wait for 5 seconds for dynamic content to load, adjust as needed\n",
    "\n",
    "            # Get the page source and create BeautifulSoup object\n",
    "            page_source = driver2.page_source\n",
    "            soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "            # Continue with extracting data as before\n",
    "            rankings_table = soup.find(\"table\", {\"class\": \"mega-table\"})\n",
    "            rows = rankings_table.find_all(\"tr\")[1:]  # Skip the header row\n",
    "\n",
    "            # Create a CSV file for each date and save the data\n",
    "            filename = os.path.join(output_folder, f\"rankings_data_{date}.csv\")\n",
    "            with open(filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([\"Rank\", \"Player\", \"Age\", \"Points\", \"Tournaments Played\"])\n",
    "\n",
    "                for row in rows:\n",
    "                    rank = row.find(\"td\", {\"class\": \"rank-cell\"}).text.strip()\n",
    "                    player_name = row.find(\"td\", {\"class\": \"player-cell\"}).text.strip()\n",
    "                    age = row.find(\"td\", {\"class\": \"age-cell\"}).text.strip()\n",
    "                    points = row.find(\"td\", {\"class\": \"points-cell\"}).text.strip()\n",
    "                    tournaments_played = row.find(\"td\", {\"class\": \"tourn-cell\"}).text.strip()\n",
    "\n",
    "                    writer.writerow([rank, player_name, age, points, tournaments_played])\n",
    "\n",
    "            print(f\"Rank Range: 1-5000, Rank Date: {date} - Data saved to {filename}\")\n",
    "            print()\n",
    "\n",
    "finally:\n",
    "    # Don't forget to stop the service once you are done.\n",
    "    service.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74734622",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALESSANDRO\\AppData\\Local\\Temp\\ipykernel_13144\\3261235652.py:8: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=chrome_driver_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year Turned Pro: 2008\n",
      "Weight (kg): 78kg\n",
      "Height (cm): 180cm\n",
      "City of Birthplace: Zevenaar\n",
      "Country of Birthplace: Netherlands\n",
      "Hand: Right-Handed\n",
      "Backhand: Two-Handed Backhand\n",
      "Coaches:\n",
      "Coach 1: Rob Morgan\n",
      "Coach 2: Mariusz Fyrstenberg\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Path to the ChromeDriver executable\n",
    "chrome_driver_path = \"C:\\\\Users\\\\ALESSANDRO\\\\Downloads\\\\chromedriver.exe\"\n",
    "\n",
    "# Initialize Chrome WebDriver\n",
    "driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "\n",
    "try:\n",
    "    url = \"https://www.atptour.com/en/players/wesley-koolhof/kc41/overview\"\n",
    "\n",
    "    # Open the URL using Selenium\n",
    "    driver.get(url)\n",
    "\n",
    "    # Get the page source after the dynamic content has loaded\n",
    "    page_source = driver.page_source\n",
    "\n",
    "    # Parse the HTML content of the page using BeautifulSoup\n",
    "    soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "    # Find the player profile hero table\n",
    "    player_hero_table = soup.find(\"div\", class_=\"player-profile-hero-table\")\n",
    "\n",
    "    # Find the div with class \"table-big-label\" for \"Turned Pro\"\n",
    "    turned_pro_label_div = player_hero_table.find(\"div\", class_=\"table-big-label\", text=\"Turned Pro\")\n",
    "\n",
    "    # Extract the \"Turned Pro\" information\n",
    "    year_pro_div = turned_pro_label_div.find_next_sibling(\"div\", class_=\"table-big-value\")\n",
    "    year_pro = year_pro_div.get_text(strip=True)\n",
    "    \n",
    "    # Find the span with class \"table-weight-kg-wrapper\" for weight in kg\n",
    "    weight_span = player_hero_table.select_one(\"span.table-weight-kg-wrapper\")\n",
    "\n",
    "    # Extract weight in kg information\n",
    "    weight_kg = \"\"\n",
    "    if weight_span:\n",
    "        weight_kg = weight_span.get_text(strip=True).strip(\"()\")\n",
    "\n",
    "    # Find the span with class \"table-height-cm-wrapper\" for height in cm\n",
    "    height_span = player_hero_table.select_one(\"span.table-height-cm-wrapper\")\n",
    "\n",
    "    # Extract height in cm information\n",
    "    height_cm = \"\"\n",
    "    if height_span:\n",
    "        height_cm = height_span.get_text(strip=True).strip(\"()\")\n",
    "\n",
    "    # Find the player birthplace div with class \"table-value\"\n",
    "    birthplace_div = soup.find(\"div\", class_=\"table-value\")\n",
    "\n",
    "    # Extract birthplace information\n",
    "    birthplace = birthplace_div.get_text(strip=True)\n",
    "\n",
    "    # Split the birthplace into city and country\n",
    "    city_birthplace, country_birthplace = birthplace.split(\",\")\n",
    "\n",
    "    # Remove any leading or trailing whitespaces from city and country\n",
    "    city_birthplace = city_birthplace.strip()\n",
    "    country_birthplace = country_birthplace.strip()\n",
    "\n",
    "    # Find the second \"div\" with class \"table-value\" for hand and backhand\n",
    "    hand_backhand_div = player_hero_table.find_all(\"div\", class_=\"table-value\")[1]\n",
    "    \n",
    "    # Extract hand and backhand information if available\n",
    "    hand, backhand = \"\", \"\"\n",
    "    if hand_backhand_div:\n",
    "        hand, backhand = [item.strip() for item in hand_backhand_div.get_text(strip=True).split(\",\")]\n",
    "\n",
    "    # Find the third \"div\" with class \"table-value\" for coach information\n",
    "    coach_div = player_hero_table.find_all(\"div\", class_=\"table-value\")[2]\n",
    "\n",
    "    # Extract coach information if available\n",
    "    coaches = coach_div.get_text(strip=True).split(\", \")\n",
    "\n",
    "    # Print the extracted information\n",
    "    print(f\"Year Turned Pro: {year_pro}\")\n",
    "    print(f\"Weight (kg): {weight_kg}\")\n",
    "    print(f\"Height (cm): {height_cm}\")\n",
    "    print(f\"City of Birthplace: {city_birthplace}\")\n",
    "    print(f\"Country of Birthplace: {country_birthplace}\")\n",
    "    print(f\"Hand: {hand}\")\n",
    "    print(f\"Backhand: {backhand}\")\n",
    "    print(\"Coaches:\")\n",
    "    for idx, coach in enumerate(coaches, 1):\n",
    "        print(f\"Coach {idx}: {coach}\")\n",
    "\n",
    "finally:\n",
    "    # Don't forget to close the WebDriver once you are done.\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8695dae3",
   "metadata": {},
   "source": [
    "combine the two chunk above in order to get all the information for each player in the rank table. (Test the first 10 players of the last 2023 tournament)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f877a590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank Range: 1-5000, Rank Date: 2023-01-30 - Data saved to C:\\Users\\ALESSANDRO\\Documents\\GitHub\\tennis-homophily\\data\\atp\\rankings_data_2023-01-30.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "\n",
    "def get_highest_dates(date_list):\n",
    "    highest_dates = {}\n",
    "    for date in date_list:\n",
    "        year_month = date[:7]\n",
    "        if year_month not in highest_dates:\n",
    "            highest_dates[year_month] = date\n",
    "        else:\n",
    "            current_date = highest_dates[year_month]\n",
    "            if date > current_date:\n",
    "                highest_dates[year_month] = date\n",
    "    return list(highest_dates.values())\n",
    "\n",
    "# Path to the ChromeDriver executable\n",
    "chrome_driver_path = \"C:\\\\Users\\\\ALESSANDRO\\\\Downloads\\\\chromedriver.exe\"\n",
    "\n",
    "# Use the Service object for ChromeDriver\n",
    "service = Service(chrome_driver_path)\n",
    "\n",
    "try:\n",
    "    # Initialize the list of dates to be scraped\n",
    "    date_values = []\n",
    "\n",
    "    # Open the first part to get the list of dates\n",
    "    with webdriver.Chrome(service=service) as driver1:\n",
    "        # Open the URL and wait for the content to load\n",
    "        driver1.get(\"https://www.atptour.com/en/rankings/doubles?rankRange=1-5000\")\n",
    "        WebDriverWait(driver1, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"mega-table\")))\n",
    "\n",
    "        # Find the date dropdown menu and retrieve the date options\n",
    "        date_dropdown_ul = WebDriverWait(driver1, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"ul[data-value='rankDate']\"))\n",
    "        )\n",
    "        date_options = date_dropdown_ul.find_elements(By.TAG_NAME, \"li\")\n",
    "\n",
    "        # Extract date values from the dropdown and store them in a list - applying year filter\n",
    "        for option in date_options:\n",
    "            date_value = option.get_attribute(\"data-value\")\n",
    "            if date_value is None:\n",
    "                continue\n",
    "            try:\n",
    "                year = int(date_value[:4])\n",
    "            except ValueError:\n",
    "                continue\n",
    "            if year == 2023:\n",
    "                date_values.append(date_value)\n",
    "\n",
    "    # Filter the dates to keep only the highest number for each pair of year and month\n",
    "    filtered_dates = get_highest_dates(date_values)\n",
    "\n",
    "    # Use only one date for testing purposes\n",
    "    filtered_dates = [filtered_dates[-1]]\n",
    "\n",
    "    # Now, loop through different dates and scrape the data\n",
    "    for date in filtered_dates:\n",
    "        # Create a CSV file for each date and save the data\n",
    "        output_folder = \"C:\\\\Users\\\\ALESSANDRO\\\\Documents\\\\GitHub\\\\tennis-homophily\\\\data\\\\atp\"\n",
    "        filename = os.path.join(output_folder, f\"rankings_data_{date}.csv\")\n",
    "        with open(filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Rank\", \"Player\", \"Age\", \"Points\", \"Tournaments Played\", \"Year Turned Pro\", \"Weight (kg)\", \"Height (cm)\", \"City of Birthplace\", \"Country of Birthplace\", \"Hand\", \"Backhand\", \"Coach1\", \"Coach2\"])\n",
    "\n",
    "            # Open a new WebDriver for each date\n",
    "            with webdriver.Chrome(service=service) as driver2:\n",
    "                # Form the complete URL with the selected date\n",
    "                complete_url = f\"https://www.atptour.com/en/rankings/doubles?rankRange=1-5000&rankDate={date}\"\n",
    "\n",
    "                # Open the URL and wait for the content to load\n",
    "                driver2.get(complete_url)\n",
    "                time.sleep(5)  # Wait for 5 seconds for dynamic content to load, adjust as needed\n",
    "\n",
    "                # Get the page source and create BeautifulSoup object\n",
    "                page_source = driver2.page_source\n",
    "                soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "                # Continue with extracting data as before\n",
    "                rankings_table = soup.find(\"table\", {\"class\": \"mega-table\"})\n",
    "#                 rows = rankings_table.find_all(\"tr\")[1:]  # Skip the header row\n",
    "                rows = rankings_table.find_all(\"tr\")[1:11]  # Process only the first 10 rows\n",
    "\n",
    "\n",
    "                for row in rows:\n",
    "                    rank = row.find(\"td\", {\"class\": \"rank-cell\"}).text.strip()\n",
    "                    player_name = row.find(\"td\", {\"class\": \"player-cell\"}).text.strip()\n",
    "                    age = row.find(\"td\", {\"class\": \"age-cell\"}).text.strip()\n",
    "                    points = row.find(\"td\", {\"class\": \"points-cell\"}).text.strip()\n",
    "                    tournaments_played = row.find(\"td\", {\"class\": \"tourn-cell\"}).text.strip()\n",
    "\n",
    "                    # Extract player profile link\n",
    "                    player_profile_link = row.find(\"a\", href=True)[\"href\"]\n",
    "\n",
    "                    # Open the player profile URL\n",
    "                    with webdriver.Chrome(service=service) as driver3:\n",
    "                        driver3.get(f\"https://www.atptour.com{player_profile_link}\")\n",
    "                        time.sleep(5)  # Wait for 5 seconds for dynamic content to load, adjust as needed\n",
    "\n",
    "                        # Get the player profile page source and create BeautifulSoup object\n",
    "                        player_page_source = driver3.page_source\n",
    "                        soup_player = BeautifulSoup(player_page_source, \"html.parser\")\n",
    "\n",
    "                        # Continue with extracting player information\n",
    "                        birthplace_div = soup_player.find(\"div\", class_=\"table-value\")\n",
    "                        birthplace = birthplace_div.get_text(strip=True)\n",
    "                        city_birthplace, _, country_birthplace = birthplace.partition(\",\")\n",
    "\n",
    "                        turned_pro_label_div = soup_player.find(\"div\", class_=\"table-big-label\", text=\"Turned Pro\")\n",
    "                        year_pro_div = turned_pro_label_div.find_next_sibling(\"div\", class_=\"table-big-value\")\n",
    "                        year_pro = year_pro_div.get_text(strip=True)\n",
    "\n",
    "                        weight_span = soup_player.select_one(\"span.table-weight-kg-wrapper\")\n",
    "                        weight_kg = \"\"\n",
    "                        if weight_span:\n",
    "                            weight_kg = weight_span.get_text(strip=True).strip(\"()\")\n",
    "\n",
    "                        height_span = soup_player.select_one(\"span.table-height-cm-wrapper\")\n",
    "                        height_cm = \"\"\n",
    "                        if height_span:\n",
    "                            height_cm = height_span.get_text(strip=True).strip(\"()\")\n",
    "\n",
    "                        # Find the div with class \"table-value\" for hand and backhand\n",
    "                        hand_backhand_div = soup_player.find_all(\"div\", class_=\"table-value\")[1]\n",
    "\n",
    "                        # Extract hand and backhand information if available\n",
    "                        hand, backhand = \"\", \"\"\n",
    "                        if hand_backhand_div:\n",
    "                            hand, backhand = [item.strip() for item in hand_backhand_div.get_text(strip=True).split(\",\")]\n",
    "\n",
    "                        # Find the div with class \"table-value\" for coach information\n",
    "                        coach_div = soup_player.find_all(\"div\", class_=\"table-value\")[2]\n",
    "\n",
    "                        # Extract coach information if available\n",
    "                        coaches = coach_div.get_text(strip=True).split(\", \")\n",
    "                        coach1 = coaches[0]\n",
    "                        coach2 = \"\" if len(coaches) < 2 else coaches[1]\n",
    "\n",
    "\n",
    "                        writer.writerow([rank, player_name, age, points, tournaments_played, year_pro, weight_kg, height_cm, city_birthplace, country_birthplace, hand, backhand, coach1, coach2])\n",
    "\n",
    "        print(f\"Rank Range: 1-5000, Rank Date: {date} - Data saved to {filename}\")\n",
    "        print()\n",
    "\n",
    "finally:\n",
    "    # Don't forget to stop the Service once you are done.\n",
    "    service.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
