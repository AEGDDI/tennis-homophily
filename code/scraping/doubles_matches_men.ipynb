{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for australian-open in year: 2018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: DeprecationWarning: Firefox will soon stop logging to geckodriver.log by default; Specify desired logs with log_output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for australian-open in year: 2019\n",
      "Scraping data for australian-open in year: 2020\n",
      "Scraping data for australian-open in year: 2021\n",
      "Scraping data for australian-open in year: 2022\n",
      "Scraping data for australian-open in year: 2023\n",
      "Scraping data for roland-garros in year: 2018\n",
      "Scraping data for roland-garros in year: 2019\n",
      "Scraping data for roland-garros in year: 2020\n",
      "Scraping data for roland-garros in year: 2021\n",
      "Scraping data for roland-garros in year: 2022\n",
      "Scraping data for roland-garros in year: 2023\n",
      "Scraping data for wimbledon in year: 2018\n",
      "Scraping data for wimbledon in year: 2019\n",
      "Scraping data for wimbledon in year: 2020\n",
      "Timeout while waiting for matches to load for wimbledon in 2020\n",
      "Scraping data for wimbledon in year: 2021\n",
      "Scraping data for wimbledon in year: 2022\n",
      "Scraping data for wimbledon in year: 2023\n",
      "Scraping data for us-open in year: 2018\n",
      "Scraping data for us-open in year: 2019\n",
      "Scraping data for us-open in year: 2020\n",
      "Scraping data for us-open in year: 2021\n",
      "Scraping data for us-open in year: 2022\n",
      "Scraping data for us-open in year: 2023\n",
      "Extracted DataFrame:\n",
      "           tournament                location                   date  year  \\\n",
      "0     Australian Open     Melbourne,Australia        15-28 Jan, 2018  2018   \n",
      "1     Australian Open     Melbourne,Australia        15-28 Jan, 2018  2018   \n",
      "2     Australian Open     Melbourne,Australia        15-28 Jan, 2018  2018   \n",
      "3     Australian Open     Melbourne,Australia        15-28 Jan, 2018  2018   \n",
      "4     Australian Open     Melbourne,Australia        15-28 Jan, 2018  2018   \n",
      "...               ...                     ...                    ...   ...   \n",
      "1400          US Open  New York,United States  28 Aug - 10 Sep, 2023  2023   \n",
      "1401          US Open  New York,United States  28 Aug - 10 Sep, 2023  2023   \n",
      "1402          US Open  New York,United States  28 Aug - 10 Sep, 2023  2023   \n",
      "1403          US Open  New York,United States  28 Aug - 10 Sep, 2023  2023   \n",
      "1404          US Open  New York,United States  28 Aug - 10 Sep, 2023  2023   \n",
      "\n",
      "     tournament_code            stage match_duration  \\\n",
      "0                580          Finals        01:33:00   \n",
      "1                580     Semi-Finals        02:26:00   \n",
      "2                580     Semi-Finals        01:29:00   \n",
      "3                580  Quarter-Finals        01:06:00   \n",
      "4                580  Quarter-Finals        02:40:00   \n",
      "...              ...              ...            ...   \n",
      "1400             560     Round of 64        01:21:00   \n",
      "1401             560     Round of 64        01:07:00   \n",
      "1402             560     Round of 64        02:05:00   \n",
      "1403             560     Round of 64        01:28:00   \n",
      "1404             560     Round of 64        01:41:00   \n",
      "\n",
      "                    winners_p1          winners_p2             losers_p1  ...  \\\n",
      "0             Oliver Marach(7)       Mate Pavic(7)  Juan Sebastian Cabal  ...   \n",
      "1             Oliver Marach(7)       Mate Pavic(7)         Ben McLachlan  ...   \n",
      "2     Juan Sebastian Cabal(11)    Robert Farah(11)             Bob Bryan  ...   \n",
      "3                 Bob Bryan(6)       Mike Bryan(6)      Marcin Matkowski  ...   \n",
      "4             Oliver Marach(7)       Mate Pavic(7)        Marcus Daniell  ...   \n",
      "...                        ...                 ...                   ...  ...   \n",
      "1400          Vasil Kirkov(WC)     Denis Kudla(WC)      Alexandre Muller  ...   \n",
      "1401          Adrian Mannarino  Arthur Rinderknech       Eliot Spizzirri  ...   \n",
      "1402             Ben McLachlan  Yoshihito Nishioka       Alexander Erler  ...   \n",
      "1403              Andreas Mies  Mackenzie McDonald           Arthur Fils  ...   \n",
      "1404        Stefanos Tsitsipas    Petros Tsitsipas   Miguel Reyes-Varela  ...   \n",
      "\n",
      "     losers_set1_tiebreak losers_set2_tiebreak losers_set3_tiebreak  \\\n",
      "0                    None                 None                 None   \n",
      "1                    None                 None                    4   \n",
      "2                       1                 None                 None   \n",
      "3                    None                 None                 None   \n",
      "4                    None                 None                    5   \n",
      "...                   ...                  ...                  ...   \n",
      "1400                 None                 None                 None   \n",
      "1401                 None                 None                 None   \n",
      "1402                 None                 None                 None   \n",
      "1403                    4                 None                 None   \n",
      "1404                    2                 None                 None   \n",
      "\n",
      "     winners_set4 winners_set5 losers_set4 losers_set5 winners_set4_tiebreak  \\\n",
      "0             NaN          NaN         NaN         NaN                   NaN   \n",
      "1             NaN          NaN         NaN         NaN                   NaN   \n",
      "2             NaN          NaN         NaN         NaN                   NaN   \n",
      "3             NaN          NaN         NaN         NaN                   NaN   \n",
      "4             NaN          NaN         NaN         NaN                   NaN   \n",
      "...           ...          ...         ...         ...                   ...   \n",
      "1400          NaN          NaN         NaN         NaN                   NaN   \n",
      "1401          NaN          NaN         NaN         NaN                   NaN   \n",
      "1402          NaN          NaN         NaN         NaN                   NaN   \n",
      "1403          NaN          NaN         NaN         NaN                   NaN   \n",
      "1404          NaN          NaN         NaN         NaN                   NaN   \n",
      "\n",
      "     losers_set4_tiebreak losers_set5_tiebreak  \n",
      "0                     NaN                  NaN  \n",
      "1                     NaN                  NaN  \n",
      "2                     NaN                  NaN  \n",
      "3                     NaN                  NaN  \n",
      "4                     NaN                  NaN  \n",
      "...                   ...                  ...  \n",
      "1400                  NaN                  NaN  \n",
      "1401                  NaN                  NaN  \n",
      "1402                  NaN                  NaN  \n",
      "1403                  NaN                  NaN  \n",
      "1404                  NaN                  NaN  \n",
      "\n",
      "[1405 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "from getpass import getuser\n",
    "import pandas as pd\n",
    "from selenium.webdriver import Firefox\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "user = getuser()\n",
    "\n",
    "# Paths and folders\n",
    "geckodriver_driver_path = f\"C:/Users/{user}/Downloads/geckodriver.exe\"\n",
    "firefox_binary_path = f\"C:/Users/{user}/AppData/Local/Mozilla Firefox/firefox.exe\"  # Update with the correct path to Firefox binary\n",
    "output_folder = f\"C:/Users/{user}/Documents/GitHub/tennis-homophily/data/atp\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "def configure_driver():\n",
    "    options = Options()\n",
    "    options.binary_location = firefox_binary_path\n",
    "    # options.add_argument(\"--headless\")  # Uncomment to run headless Firefox\n",
    "    service = Service(geckodriver_driver_path)\n",
    "    return Firefox(service=service, options=options)\n",
    "\n",
    "def random_sleep(min_seconds=1, max_seconds=5):\n",
    "    time.sleep(random.uniform(min_seconds, max_seconds))\n",
    "\n",
    "def scrape_matches_for_tournament_and_year(tournament_name, tournament_code, year):\n",
    "    driver = configure_driver()\n",
    "    ranking_url = f\"https://www.atptour.com/en/scores/archive/{tournament_name}/{tournament_code}/{year}/results?matchType=doubles\"\n",
    "    driver.get(ranking_url)\n",
    "    random_sleep()  # Random sleep to mimic human behavior\n",
    "\n",
    "    try:\n",
    "        # Wait for the matches to load\n",
    "        WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \".match\"))\n",
    "        )\n",
    "    except TimeoutException:\n",
    "        print(f\"Timeout while waiting for matches to load for {tournament_name} in {year}\")\n",
    "        driver.quit()\n",
    "        return []\n",
    "\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "    \n",
    "    complete_rows = []\n",
    "    \n",
    "    # Extract tournament information\n",
    "    try:\n",
    "        tournament_div = soup.find(\"div\", class_=\"header\").find(\"h3\", class_=\"title\")\n",
    "        tournament = tournament_div.get_text(strip=True) if tournament_div else None\n",
    "    except NoSuchElementException:\n",
    "        tournament = None\n",
    "    \n",
    "    # Extract location and date information\n",
    "    try:\n",
    "        schedule_div = soup.find(\"div\", class_=\"schedule\")\n",
    "        date_location_div = schedule_div.find(\"div\", class_=\"date-location\")\n",
    "        spans = date_location_div.find_all(\"span\")\n",
    "        location = spans[0].get_text(strip=True) if len(spans) > 0 else None\n",
    "        date = spans[1].get_text(strip=True) if len(spans) > 1 else None\n",
    "    except NoSuchElementException:\n",
    "        location = None\n",
    "        date = None\n",
    "    \n",
    "    # Find all divs with class \"match\"\n",
    "    matches = soup.find_all(\"div\", class_=\"match\")\n",
    "    \n",
    "    for match in matches:\n",
    "        row = {\"tournament\": tournament, \"location\": location, \"date\": date, \"year\": year, \"tournament_code\": tournament_code}\n",
    "        \n",
    "        # Find the match-header inside each match\n",
    "        match_header = match.find(\"div\", class_=\"match-header\")\n",
    "        if match_header:\n",
    "            spans = match_header.find_all(\"span\")\n",
    "            if len(spans) > 1:\n",
    "                stage_text = spans[0].get_text(strip=True).replace(\"\\n\", \"\")\n",
    "                if stage_text.endswith(\"-\"):\n",
    "                    stage_text = stage_text[:-1]\n",
    "                row[\"stage\"] = stage_text\n",
    "                row[\"match_duration\"] = spans[1].get_text(strip=True).replace(\"\\n\", \"\")\n",
    "        \n",
    "        # Find the players' names inside each match\n",
    "        match_content = match.find(\"div\", class_=\"match-content\")\n",
    "        if match_content:\n",
    "            players = match_content.find_all(\"div\", class_=\"players\")\n",
    "            if len(players) > 1:\n",
    "                # Extract winners\n",
    "                winners_names = players[0].find(\"div\", class_=\"names\")\n",
    "                if winners_names:\n",
    "                    winner_name_divs = winners_names.find_all(\"div\", class_=\"name\")\n",
    "                    if len(winner_name_divs) > 1:\n",
    "                        row[\"winners_p1\"] = winner_name_divs[0].get_text(strip=True).replace(\"\\n\", \"\")\n",
    "                        row[\"winners_p2\"] = winner_name_divs[1].get_text(strip=True).replace(\"\\n\", \"\")\n",
    "                \n",
    "                # Extract losers\n",
    "                losers_names = players[1].find(\"div\", class_=\"names\")\n",
    "                if losers_names:\n",
    "                    loser_name_divs = losers_names.find_all(\"div\", class_=\"name\")\n",
    "                    if len(loser_name_divs) > 1:\n",
    "                        row[\"losers_p1\"] = loser_name_divs[0].get_text(strip=True).replace(\"\\n\", \"\")\n",
    "                        row[\"losers_p2\"] = loser_name_divs[1].get_text(strip=True).replace(\"\\n\", \"\")\n",
    "        \n",
    "        # Extract scores\n",
    "        scores = match_content.find_all(\"div\", class_=\"scores\")\n",
    "        if len(scores) > 1:\n",
    "            # Initialize scores and tiebreaks\n",
    "            row[\"winners_set1\"], row[\"winners_set2\"], row[\"winners_set3\"] = None, None, None\n",
    "            row[\"winners_set1_tiebreak\"], row[\"winners_set2_tiebreak\"], row[\"winners_set3_tiebreak\"] = None, None, None\n",
    "            row[\"losers_set1\"], row[\"losers_set2\"], row[\"losers_set3\"] = None, None, None\n",
    "            row[\"losers_set1_tiebreak\"], row[\"losers_set2_tiebreak\"], row[\"losers_set3_tiebreak\"] = None, None, None\n",
    "\n",
    "            # Extract winners' scores, starting from the second element\n",
    "            winner_scores = scores[0].find_all(\"div\", class_=\"score-item\")[1:]\n",
    "            for i in range(len(winner_scores)):  # Ensure sets are filled sequentially\n",
    "                spans = winner_scores[i].find_all(\"span\")\n",
    "                row[f\"winners_set{i+1}\"] = spans[0].get_text(strip=True).replace(\"\\n\", \"\") if spans else None\n",
    "                if len(spans) > 1:\n",
    "                    row[f\"winners_set{i+1}_tiebreak\"] = spans[1].get_text(strip=True).replace(\"\\n\", \"\")\n",
    "            \n",
    "            # Extract losers' scores, starting from the second element\n",
    "            loser_scores = scores[1].find_all(\"div\", class_=\"score-item\")[1:]\n",
    "            for i in range(len(loser_scores)):  # Ensure sets are filled sequentially\n",
    "                spans = loser_scores[i].find_all(\"span\")\n",
    "                row[f\"losers_set{i+1}\"] = spans[0].get_text(strip=True).replace(\"\\n\", \"\") if spans else None\n",
    "                if len(spans) > 1:\n",
    "                    row[f\"losers_set{i+1}_tiebreak\"] = spans[1].get_text(strip=True).replace(\"\\n\", \"\")\n",
    "        \n",
    "        # Only add complete rows to the list\n",
    "        if all(key in row for key in [\"stage\", \"match_duration\", \"winners_p1\", \"winners_p2\", \"losers_p1\", \"losers_p2\",\n",
    "                                      \"winners_set1\", \"winners_set2\", \"winners_set3\", \"losers_set1\", \"losers_set2\", \"losers_set3\",\n",
    "                                      \"winners_set1_tiebreak\", \"winners_set2_tiebreak\", \"winners_set3_tiebreak\",\n",
    "                                      \"losers_set1_tiebreak\", \"losers_set2_tiebreak\", \"losers_set3_tiebreak\"]):\n",
    "            complete_rows.append(row)\n",
    "\n",
    "    driver.quit()\n",
    "    \n",
    "    return complete_rows\n",
    "\n",
    "# Grand Slam tournaments and their codes\n",
    "tournaments = {\n",
    "    \"australian-open\": \"580\",\n",
    "    \"roland-garros\": \"520\",\n",
    "    \"wimbledon\": \"540\",\n",
    "    \"us-open\": \"560\"\n",
    "}\n",
    "\n",
    "# Scrape match data for each tournament and year, and combine into a single DataFrame\n",
    "all_rows = []\n",
    "for tournament_name, tournament_code in tournaments.items():\n",
    "    for year in range(2018, 2023+1):\n",
    "        print(f\"Scraping data for {tournament_name} in year: {year}\")\n",
    "        rows = scrape_matches_for_tournament_and_year(tournament_name, tournament_code, year)\n",
    "        all_rows.extend(rows)\n",
    "\n",
    "# Create a DataFrame from all rows\n",
    "df = pd.DataFrame(all_rows)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "output_file = os.path.join(output_folder, \"grand_slam_matches_2018_2023.xlsx\")\n",
    "df.to_excel(output_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(\"Extracted DataFrame:\")\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
