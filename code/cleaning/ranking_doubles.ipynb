{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53b4ecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from getpass import getuser\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cc99636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 files.\n",
      "Processed: ranking_doubles_2018-01-15.xlsx\n",
      "Processed: ranking_doubles_2018-05-21.xlsx\n",
      "Processed: ranking_doubles_2018-07-02.xlsx\n",
      "Processed: ranking_doubles_2018-09-24.xlsx\n",
      "Processed: ranking_doubles_2019-01-14.xlsx\n",
      "Processed: ranking_doubles_2019-05-20.xlsx\n",
      "Processed: ranking_doubles_2019-07-01.xlsx\n",
      "Processed: ranking_doubles_2019-08-26.xlsx\n",
      "Processed: ranking_doubles_2020-01-20.xlsx\n",
      "Processed: ranking_doubles_2020-08-31.xlsx\n",
      "Processed: ranking_doubles_2020-09-21.xlsx\n",
      "Processed: ranking_doubles_2021-02-08.xlsx\n",
      "Processed: ranking_doubles_2021-05-24.xlsx\n",
      "Processed: ranking_doubles_2021-06-28.xlsx\n",
      "Processed: ranking_doubles_2021-08-30.xlsx\n",
      "Processed: ranking_doubles_2022-01-17.xlsx\n",
      "Processed: ranking_doubles_2022-05-16.xlsx\n",
      "Processed: ranking_doubles_2022-06-27.xlsx\n",
      "Processed: ranking_doubles_2022-08-22.xlsx\n",
      "Processed: ranking_doubles_2023-01-16.xlsx\n",
      "Processed: ranking_doubles_2023-05-22.xlsx\n",
      "Processed: ranking_doubles_2023-07-03.xlsx\n",
      "Processed: ranking_doubles_2023-08-28.xlsx\n",
      "Rows per file: [999, 999, 999, 999, 892, 876, 888, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 499, 999, 999, 999, 499, 999]\n",
      "Expected total rows: 21636\n",
      "Actual merged rows: 21636\n",
      "✅ Row count matches! No rows lost or duplicated during merge.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "USER = getuser()\n",
    "INPUT_DIR = f\"C:/Users/{USER}/Documents/GitHub/tennis-homophily/data/atp/\"\n",
    "\n",
    "# Collect all ranking_doubles files\n",
    "files = [\n",
    "    f for f in os.listdir(INPUT_DIR)\n",
    "    if f.startswith(\"ranking_doubles_\") and f.endswith(\".xlsx\")\n",
    "]\n",
    "\n",
    "print(f\"Found {len(files)} files.\")\n",
    "\n",
    "dfs = []\n",
    "for file in sorted(files):\n",
    "    path = os.path.join(INPUT_DIR, file)\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_excel(path)\n",
    "\n",
    "        # Drop unwanted columns if they exist\n",
    "        cols_to_drop = [\"Unnamed: 15\", \"Player Profile Link\"]\n",
    "        df = df.drop(columns=[c for c in cols_to_drop if c in df.columns], errors=\"ignore\")\n",
    "        \n",
    "        # Standardize column names: lower case + replace space with -\n",
    "        df.columns = df.columns.str.lower().str.replace(\" \", \"-\", regex=False)\n",
    "\n",
    "        dfs.append(df)\n",
    "        print(f\"Processed: {file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "\n",
    "# Count rows in each single df\n",
    "rows_per_df = [len(d) for d in dfs]\n",
    "\n",
    "# Total expected rows\n",
    "expected_rows = sum(rows_per_df)\n",
    "\n",
    "print(\"Rows per file:\", rows_per_df)\n",
    "print(\"Expected total rows:\", expected_rows)\n",
    "\n",
    "# Merge\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "actual_rows = len(merged_df)\n",
    "\n",
    "print(\"Actual merged rows:\", actual_rows)\n",
    "\n",
    "if actual_rows == expected_rows:\n",
    "    print(\"✅ Row count matches! No rows lost or duplicated during merge.\")\n",
    "else:\n",
    "    print(\"❌ Mismatch! Expected:\", expected_rows, \"but got:\", actual_rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469222da",
   "metadata": {},
   "source": [
    "# clear players'names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5f69482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clean all columns starting with 'player'\n",
    "player_cols = [col for col in merged_df.columns if col.startswith(\"player\")]\n",
    "\n",
    "def clean_player_name(x):\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    x = str(x).lower().strip()\n",
    "\n",
    "    # remove prefixes like \"1R. \", \"1O. \", \"-1R. \", etc.\n",
    "    x = re.sub(r\"^[\\-\\d]*[a-zA-Z]\\.\\s*\", \"\", x)  # removes \"L. \", \"R. \", \"1O. \", \"-1R. \" etc.\n",
    "\n",
    "    # remove numeric or alphanumeric blocks before surname\n",
    "    # examples: \"1r. harrison\", \"1. harrison\", \"2q. garcia\"\n",
    "    x = re.sub(r\"^[\\-\\d]*[a-zA-Z]*\\d*\\.\\s*\", \"\", x)\n",
    "\n",
    "    # ensure surname only (in case initials remain)\n",
    "    # e.g. \"l.kubot\" -> \"kubot\"\n",
    "    x = re.sub(r\"^[a-z]\\.\", \"\", x).strip()\n",
    "\n",
    "    return x\n",
    "\n",
    "for col in player_cols:\n",
    "    merged_df[col] = merged_df[col].apply(clean_player_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288fe4e4",
   "metadata": {},
   "source": [
    "# split w-l columns in two separate variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fca157c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W-L columns successfully split.\n"
     ]
    }
   ],
   "source": [
    "# Identify all W-L columns in merged_df\n",
    "wl_cols = [col for col in merged_df.columns if col.startswith(\"w-l-\")]\n",
    "\n",
    "def split_wl(value):\n",
    "    \"\"\"\n",
    "    Converts strings like '24 - 28' or '435-305' into (24, 28).\n",
    "    Returns (None, None) if parsing fails.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return (None, None)\n",
    "\n",
    "    value = str(value).strip()\n",
    "\n",
    "    # Extract two numbers\n",
    "    match = re.findall(r\"\\d+\", value)\n",
    "    if len(match) == 2:\n",
    "        return int(match[0]), int(match[1])\n",
    "    else:\n",
    "        return (None, None)\n",
    "\n",
    "for col in wl_cols:\n",
    "    # Example: w-l-ytd → ytd\n",
    "    suffix = col.replace(\"w-l-\", \"\")\n",
    "\n",
    "    # Create new columns\n",
    "    merged_df[f\"w-{suffix}\"], merged_df[f\"l-{suffix}\"] = zip(\n",
    "        *merged_df[col].apply(split_wl)\n",
    "    )\n",
    "\n",
    "    # Remove the original column\n",
    "    merged_df.drop(columns=col, inplace=True)\n",
    "\n",
    "print(\"W-L columns successfully split.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ea7252",
   "metadata": {},
   "source": [
    "# extract the missing values of dob from age "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70229401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOB values updated where possible.\n"
     ]
    }
   ],
   "source": [
    "def extract_dob_from_age(age_value):\n",
    "    \"\"\"\n",
    "    Extracts the date inside parentheses in the format YYYY/MM/DD.\n",
    "    Example: '42 (1983/09/23)' → '1983/09/23'\n",
    "    \"\"\"\n",
    "    if pd.isna(age_value):\n",
    "        return None\n",
    "\n",
    "    age_str = str(age_value)\n",
    "\n",
    "    # Look for a date inside parentheses\n",
    "    match = re.search(r\"\\((\\d{4}/\\d{2}/\\d{2})\\)\", age_str)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "# Apply only to rows where dob is missing\n",
    "missing_dob_mask = merged_df[\"dob\"].isna()\n",
    "\n",
    "merged_df.loc[missing_dob_mask, \"dob\"] = merged_df.loc[missing_dob_mask, \"age\"].apply(\n",
    "    extract_dob_from_age\n",
    ")\n",
    "\n",
    "print(\"DOB values updated where possible.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4604d6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop(columns=[\"age\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f62fa5a",
   "metadata": {},
   "source": [
    "# weight and height split in two different measures \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "12f02324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight and height cleaned successfully.\n"
     ]
    }
   ],
   "source": [
    "# ---------- WEIGHT CLEANING ----------\n",
    "def extract_weight_lbs(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    match = re.search(r\"(\\d+)\\s*lbs\", str(x).lower())\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "def extract_weight_kg(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    match = re.search(r\"\\((\\d+)\\s*kg\\)\", str(x).lower())\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "if \"weight\" in merged_df.columns:\n",
    "    merged_df[\"weight-lbs\"] = merged_df[\"weight\"].apply(extract_weight_lbs)\n",
    "    merged_df[\"weight-kg\"]  = merged_df[\"weight\"].apply(extract_weight_kg)\n",
    "    merged_df.drop(columns=[\"weight\"], inplace=True)\n",
    "\n",
    "\n",
    "# ---------- HEIGHT CLEANING ----------\n",
    "def extract_height_ft(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    match = re.search(r\"(\\d+)'\\s*(\\d+)\\\"\", str(x).lower())\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "def extract_height_in(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    match = re.search(r\"(\\d+)'\\s*(\\d+)\\\"\", str(x).lower())\n",
    "    return int(match.group(2)) if match else None\n",
    "\n",
    "def extract_height_cm(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    match = re.search(r\"\\((\\d+)\\s*cm\\)\", str(x).lower())\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "if \"height\" in merged_df.columns:\n",
    "    merged_df[\"height-ft\"] = merged_df[\"height\"].apply(extract_height_ft)\n",
    "    merged_df[\"height-in\"] = merged_df[\"height\"].apply(extract_height_in)\n",
    "    merged_df[\"height-cm\"] = merged_df[\"height\"].apply(extract_height_cm)\n",
    "    merged_df.drop(columns=[\"height\"], inplace=True)\n",
    "\n",
    "print(\"Weight and height cleaned successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e00507",
   "metadata": {},
   "source": [
    "# variable experience = year - turned pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c2bd4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create experience variable only if both columns exist\n",
    "if \"year\" in merged_df.columns and \"turned-pro\" in merged_df.columns:\n",
    "    merged_df[\"experience\"] = merged_df[\"year\"] - merged_df[\"turned-pro\"]\n",
    "else:\n",
    "    print(\"Column 'year' or 'turned-pro' is missing.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61945b67",
   "metadata": {},
   "source": [
    "# birthplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cba336b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_birthplace(x):\n",
    "    if pd.isna(x):\n",
    "        return (None, None)\n",
    "    \n",
    "    parts = str(x).split(\",\")\n",
    "    \n",
    "    if len(parts) == 2:\n",
    "        city = parts[0].strip()\n",
    "        country = parts[1].strip()\n",
    "        return city, country\n",
    "    else:\n",
    "        # If the format is not city, country → return entire string as city\n",
    "        return str(x).strip(), None\n",
    "\n",
    "# Apply split\n",
    "merged_df[\"birthplace-city\"], merged_df[\"birthplace-country\"] = zip(\n",
    "    *merged_df[\"birthplace\"].apply(split_birthplace)\n",
    ")\n",
    "\n",
    "# Optional: drop the original column\n",
    "merged_df.drop(columns=[\"birthplace\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2473c9",
   "metadata": {},
   "source": [
    "# hand and backhand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11efa520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_plays(x):\n",
    "    if pd.isna(x):\n",
    "        return (None, None)\n",
    "    \n",
    "    parts = str(x).split(\",\")\n",
    "    \n",
    "    if len(parts) == 2:\n",
    "        hand = parts[0].strip()\n",
    "        backhand = parts[1].strip()\n",
    "        return hand, backhand\n",
    "    else:\n",
    "        # If format unexpected, store everything in \"hand\"\n",
    "        return str(x).strip(), None\n",
    "\n",
    "merged_df[\"hand\"], merged_df[\"backhand\"] = zip(\n",
    "    *merged_df[\"plays\"].apply(split_plays)\n",
    ")\n",
    "\n",
    "# Optional: drop the original column\n",
    "merged_df.drop(columns=[\"plays\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65de769f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged file saved as: C:/Users/aldi/Documents/GitHub/tennis-homophily/data/atp/men_rankings.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Save output\n",
    "output_path = os.path.join(INPUT_DIR, \"men_rankings.xlsx\")\n",
    "merged_df.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"\\nMerged file saved as: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
